---
title: "RNA-Seq Workflow Template" 
author: "Author: Daniela Cassol (danielac@ucr.edu) and Thomas Girke (thomas.girke@ucr.edu)"
date: "Last update: `r format(Sys.time(), '%d %B, %Y')`" 
output:
  BiocStyle::html_document:
    toc_float: true
    code_folding: show
package: systemPipeR
vignette: |
  %\VignetteIndexEntry{WF: RNA-Seq Workflow Template}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
fontsize: 14pt
bibliography: bibtex.bib
---

<!--
Rscript -e "rmarkdown::render('systemPipeRNAseq.Rmd', c('BiocStyle::html_document'), clean=F); knitr::knit('systemPipeRNAseq.Rmd', tangle=TRUE)"; Rscript -e "rmarkdown::render('systemPipeRNAseq.Rmd', c('BiocStyle::pdf_document'))"
-->

```{css, echo=FALSE}
pre code {
white-space: pre !important;
overflow-x: scroll !important;
word-break: keep-all !important;
word-wrap: initial !important;
}
```


```{r style, echo = FALSE, results = 'asis'}
BiocStyle::markdown()
options(width = 60, max.print = 1000)
knitr::opts_chunk$set(
    eval = as.logical(Sys.getenv("KNITR_EVAL", "TRUE")),
    cache = as.logical(Sys.getenv("KNITR_CACHE", "TRUE")), 
    tidy.opts = list(width.cutoff = 60), tidy = TRUE)
```

# Introduction

Users want to provide here background information about the design of their RNA-Seq project.

# Create the workflow

To initiate a RNAseq workflow, this entire Rmarkdown file will be imported as a 
workflow object `SYSargsList`, or referred as the `sal` object by using the 
`importWF(sal, "systemPipeRNAseq_import.Rmd")` command.

This template provides some common steps for a RNAseq workflow. One can add, remove, modify 
workflow steps by operating on the `sal` object. 
For full documentation and details of SPR features and functions, please see the 
[main vignette](http://bioconductor.org/packages/devel/bioc/vignettes/systemPipeR/inst/doc/systemPipeR.html).

```{r genNew_wf, eval=FALSE}
systemPipeRdata::genWorkenvir(workflow = "rnaseq", mydirname = "rnaseq")
setwd("rnaseq")
sal <- SPRproject() 
sal <- importWF(sal, 
                   file_path = "systemPipeRNAseq_importWF.Rmd", 
                    verbose = FALSE)
```

In this template, code chunks with option `spr='sysargs'` (command-line step) or 
`spr='r'` will be added to the workflow. Other code chunks will be ignored. 

> If you desire to build this workflow in an interactive mode, please use the 
following tutorial "systemPipeRNAseq.Rmd".

# Samples and environment settings

## Environment settings and input data

Typically, the user wants to record here the sources and versions of the
reference genome sequence along with the corresponding annotations. In
the provided sample data set all data inputs are stored in a `data`
subdirectory and all results will be written to a separate `results` directory,
while the `systemPipeRNAseq.Rmd` script and the `targets` file are expected to be 
located in the parent directory. The R session is expected to run from this parent directory.

[*systemPipeRdata*](http://bioconductor.org/packages/release/data/experiment/html/systemPipeRdata.html) package is a helper package to generate a fully populated [*systemPipeR*](http://bioconductor.org/packages/release/bioc/html/systemPipeR.html)
workflow environment in the current working directory with a single command. 
All the instruction for generating the workflow are provide in the *systemPipeRdata* vignette [here](http://www.bioconductor.org/packages/devel/data/experiment/vignettes/systemPipeRdata/inst/doc/systemPipeRdata.html#1_Introduction). 

The mini sample FASTQ files used by this report as well as the associated reference genome files
can be loaded via the *systemPipeRdata* package. 
The chosen data set [SRP010938](http://www.ncbi.nlm.nih.gov/sra/?term=SRP010938)
contains 18 paired-end (PE) read sets from *Arabidposis thaliana*
[@Howard2013-fq]. To minimize processing time during testing, each FASTQ
file has been subsetted to 90,000-100,000 randomly sampled PE reads that
map to the first 100,000 nucleotides of each chromosome of the *A.
thaliana* genome. The corresponding reference genome sequence (FASTA) and
its GFF annotation files have been truncated accordingly. This way the entire 
test sample data set is less than 200MB in storage space. A PE read set has been
chosen for this test data set for flexibility, because it can be used for testing both types
of analysis routines requiring either SE (single end) reads or PE reads.

# Start of workflow steps

By reaching this point, it is assumed that:

1. In a testing case, the workflow environment has been created by the `systemPipeRdata::genWorkenvir`.
2. In a real case, the data and content of the `targets` file have been replaced with real data. 
3. Make modifications of following steps if needed and save the file, otherwise 
   create the workflow and load the steps by 
   - `sal <- SPRproject()`
   - `systemPipeR::importWF(sal, "systemPipeRNAseq.Rmd")`.
4. If the workflow project is created by the previous step and some progress has been 
   made, to resume/continue the workflow, please use 
   `sal <- SPRproject(restart=TRUE)`. Template only needs to be imported 
   to SPR project once.

## Required packages and resources

The `systemPipeR` package needs to be loaded [@H_Backman2016-bt].

```{r load_SPR, message=FALSE, eval=TRUE, spr='r'}
library(systemPipeR)
```

# Read preprocessing

## Read trimming with Trimmomatic

Next, we need to populate the object created with the first step in the
workflow. Here, an example of how to perform this task using parameters template
files for trimming FASTQ files with [Trimmomatic](http://www.usadellab.org/cms/?page=trimmomatic) software [@Bolger2014-yr].

```{r trimming, eval=FALSE, spr='sysargs', spr.dep='load_SPR'}
targetspath <- "targetsPE.txt"
appendStep(sal) <- SYSargsList(
    step_name = "trimming",
    targets=targetspath, 
    wf_file = "trimmomatic/trimmomatic-pe.cwl", input_file = "trimmomatic/trimmomatic-pe.yml",
    dir_path= "param/cwl",
    inputvars=c(FileName1="_FASTQ_PATH1_", FileName2="_FASTQ_PATH2_", SampleName="_SampleName_"), 
    dependency = "load_SPR")
```


# Alignments

## Read mapping with `HISAT2`

The following steps will demonstrate how to use the short read aligner `Hisat2`
[@Kim2015-ve] in both interactive job submissions and batch submissions to
queuing systems of clusters using the _`systemPipeR's`_ new CWL command-line interface.

Build `Hisat2` index.

```{r hisat2_index, eval=FALSE, spr='sysargs', spr.dep='load_SPR'}
appendStep(sal) <- SYSargsList(
  step_name = "hisat2_index", dir = FALSE, targets=NULL, 
  wf_file = "hisat2/hisat2-index.cwl", 
  input_file="hisat2/hisat2-index.yml",
  dir_path="param/cwl", 
  dependency = "load_SPR"
)
```

## HISAT2 mapping

The parameter settings of the aligner are defined in the `hisat2-mapping-se.cwl` 
and `hisat2-mapping-se.yml` files. The following shows how to construct the 
corresponding *SYSargsList* object.

```{r hisat2_mapping, eval=FALSE, spr='sysargs', spr.dep='trimming;hisat2_index'}
appendStep(sal) <- SYSargsList(
  step_name = "hisat2_mapping",
  targets ="trimming", dir = TRUE, 
  wf_file = "workflow-hisat2/workflow_hisat2-pe.cwl",
  input_file = "workflow-hisat2/workflow_hisat2-pe.yml",
  dir_path = "param/cwl",
  inputvars = c(trimmomatic_1_paired = "_FASTQ_PATH1_", trimmomatic_2_paired = "_FASTQ_PATH2_", 
                SampleName = "_SampleName_"),
  rm_targets_col = c("FileName1", "FileName2"), 
  dependency = c("trimming", "hisat2_index")
)
```

## Read and alignment stats

The following provides an overview of the number of reads in each sample
and how many of them aligned to the reference.

```{r mapping_stats, eval=FALSE, spr='r', spr.dep='hisat2_mapping'}
bampaths <- getColumn(sal, step = "hisat2_mapping", "outfiles", column = "samtools_sort_bam")
fqpaths <- getColumn(sal, step = "trimming", "targetsWF", column = "FileName1")
read_statsDF <- alignStats(args=bampaths, fqpaths = fqpaths, pairEnd = TRUE)
write.table(read_statsDF, "results/alignStats.xls", row.names=FALSE, quote=FALSE, sep="\t")
```

# Read quantification

Reads overlapping with annotation ranges of interest are counted for
each sample using the `summarizeOverlaps` function [@Lawrence2013-kt]. The read counting is
preformed for exon gene regions in a non-strand-specific manner while
ignoring overlaps among different genes. Subsequently, the expression
count values are normalized by *reads per kp per million mapped reads*
(RPKM). The raw read count table (`countDFeByg.xls`) and the corresponding 
RPKM table (`rpkmDFeByg.xls`) are written to separate files in the directory of this project. Parallelization is achieved with the `BiocParallel` package, here using 8 CPU cores.

## Create a database for gene annotation

# Read counting with `summarizeOverlaps` in parallel mode using multiple cores

```{r read_counting, eval=FALSE, spr='r', spr.dep='hisat2_mapping'}
library("GenomicFeatures"); library(BiocParallel)
(function(){
  # if db is there, skip this step
  if(file.exists("./data/tair10.sqlite")) return(TRUE)
  # otherwise prepare the db
  txdb <- makeTxDbFromGFF(file="data/tair10.gff", format="gff", dataSource="TAIR", organism="Arabidopsis thaliana")
  saveDb(txdb, file="./data/tair10.sqlite")
})()
txdb <- loadDb("./data/tair10.sqlite")
outpaths <- getColumn(sal, step = "hisat2_mapping", "outfiles", column = "samtools_sort_bam")
eByg <- exonsBy(txdb, by=c("gene"))
bfl <- BamFileList(outpaths, yieldSize=50000, index=character())
multicoreParam <- MulticoreParam(workers=2); register(multicoreParam); registered()
counteByg <- bplapply(bfl, function(x) summarizeOverlaps(eByg, x, mode="Union", 
                                               ignore.strand=TRUE, 
                                               inter.feature=FALSE, 
                                               singleEnd=TRUE)) 
countDFeByg <- sapply(seq(along=counteByg), function(x) assays(counteByg[[x]])$counts)
rownames(countDFeByg) <- names(rowRanges(counteByg[[1]])); colnames(countDFeByg) <- names(bfl)
rpkmDFeByg <- apply(countDFeByg, 2, function(x) returnRPKM(counts=x, ranges=eByg))
write.table(countDFeByg, "results/countDFeByg.xls", col.names=NA, quote=FALSE, sep="\t")
write.table(rpkmDFeByg, "results/rpkmDFeByg.xls", col.names=NA, quote=FALSE, sep="\t")
```

Note, for most statistical differential expression or abundance analysis
methods, such as `edgeR` or `DESeq2`, the raw count values should be used as input. The
usage of RPKM values should be restricted to specialty applications
required by some users, *e.g.* manually comparing the expression levels
among different genes or features.


# Version Information

```{r sessionInfo, spr='r', spr.dep='read_counting'}
sessionInfo()
```

# Funding

This project was supported by funds from the National Institutes of Health (NIH).

# References
